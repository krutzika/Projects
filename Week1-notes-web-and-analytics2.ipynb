{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f06447",
   "metadata": {},
   "source": [
    "## Scraping reviews using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ef3a1",
   "metadata": {},
   "source": [
    "Here is another example of how Selenium can be used to interact with websites making use of Ajax (Asynchronous JavaScript):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9de56",
   "metadata": {},
   "source": [
    "### Selenium is a chrome automation framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871c737",
   "metadata": {},
   "source": [
    "It will enable us to tell chrome:\n",
    "* go to page bbc.co.uk/weather\n",
    "* \"click the work 'next'\"\n",
    "* scroll down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4444ce",
   "metadata": {},
   "source": [
    "Selenium will basically open a simplified version of Chrome, for a few seconds, use it and close it afterwards. You might even see it flash on your screen quickly. Then we will use beautiful soup to understand the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354eacfc",
   "metadata": {},
   "source": [
    "### BeautifulSoup is an HTML parsing framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c999f83e",
   "metadata": {},
   "source": [
    "It will enable us to:\n",
    "* copy the html of the tags eg. div, table\n",
    "* extract text from these tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f72416",
   "metadata": {},
   "source": [
    "## Getting selenium (don't skip this!)-- You need to download the chromedrive by yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab020b",
   "metadata": {},
   "source": [
    "1. find out which version of chrome you have, in chrome open page: chrome://settings/help\n",
    "2. Go to the list of selenium versions and find folder with yoru version (eg. 87.0.4280.88) https://chromedriver.storage.googleapis.com/index.html\n",
    "3. Go into the folder for your version and download the zip file with the version for your operating system (most likely `chromedriver_mac64.zip` or `chromedriver_win32.zip` ).\n",
    "4. unzip that file on yoru machine and put it in the folder where this notebook is. unzipped file will be called `chromedriver` or `chromedriver.exe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530b3964",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./opt/anaconda3/lib/python3.9/site-packages (4.7.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in ./opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: outcome in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df1f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2851b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('chromedriver') # mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9069dcb",
   "metadata": {},
   "source": [
    "**Important Note**: allowing your system to run `chromedriver`. This needs to be done just once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863764a5",
   "metadata": {},
   "source": [
    "If you are on a mac, you will need to allow your system to use chromium. Run below cell, and you will likely see a warning the first time, click 'cancel' (don't click 'Delete')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c6866",
   "metadata": {},
   "source": [
    "After you see the warning, go into `Settings > Security&Privacy > General` and `\"Allow Anyway\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea6539",
   "metadata": {},
   "source": [
    "On a pc the process will be simpler. When asked you'll need to allow computer to use the `chromedriver.exe` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c27429",
   "metadata": {},
   "source": [
    "## Task: let's try to scrape an interactive website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4613f1",
   "metadata": {},
   "source": [
    "What will be the weather in Edinburgh in 2 days?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ead1c7",
   "metadata": {},
   "source": [
    "You need a web browser, pen and paper!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a5724",
   "metadata": {},
   "source": [
    "In this task you will be asked to do something by yourself (using your web browser, mouse and keyboard), and then you will see how you cen program `Selenium` to do it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e75e3",
   "metadata": {},
   "source": [
    "**Use www.bbc.co.uk/weather to find out what time will be the sunrise in EDINBURGH next Sunday.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9589f2",
   "metadata": {},
   "source": [
    "Do it at least 3 times and observe all the steps you are taking. Make a very detailed list of all the steps, as if you had to describe them to someone over the phone without seeing their screen. See example below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3dbe8",
   "metadata": {},
   "source": [
    "it will look a bit like this:\n",
    "* ok, go to www.bbc.co.uk/weather and wait for it to load\n",
    "* scroll down, do you see a link with words 'Edinburgh' on it? Click it.\n",
    "* Wait a minute for it to load.\n",
    "* ok, now scroll down and ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c635dc0",
   "metadata": {},
   "source": [
    "When you are done with this exercise, we will try to instruct Selenium (Chrome automation tool) to do it for us. Do you think you can try to use Chrome Dev tools to make yoru steps more specific? eg. Instead of saying \"copy text in that bold link next to the word Sunrise\" try to say \"copy text from the html span item with a class `wr-c-astro-data__time`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3799f",
   "metadata": {},
   "source": [
    "**SERIOUSLY: Take a few minutes to do this. It will make you learn more from the below code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4de70",
   "metadata": {},
   "source": [
    "Ok. And now let's get the python to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2412caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunrise next Sunday:  08:01\n"
     ]
    }
   ],
   "source": [
    "browser = get_a_browser()\n",
    "\n",
    "# the url we want to open\n",
    "url = u'https://www.bbc.co.uk/weather'\n",
    "\n",
    "# the browser will start and load the webpage\n",
    "browser.get(url)\n",
    "\n",
    "# we wait 1 second to let the page load everything\n",
    "time.sleep(1)\n",
    "\n",
    "# we search for an element that is called 'customer reviews', which is a button\n",
    "# the button can be clicked with the .click() function\n",
    "browser.find_element(By.LINK_TEXT,\"Edinburgh\").click();\n",
    "\n",
    "# sleep again, let everything load\n",
    "time.sleep(1)\n",
    "\n",
    "# we load the HTML body (the main page content without headers, footers, etc.)\n",
    "body = browser.find_element(By.TAG_NAME,'body')\n",
    "\n",
    "# we use seleniums' send_keys() function to physically scroll down where we want to click\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "# search for the next button to access the next reviews\n",
    "try:\n",
    "    # link will look like \"Sun 12Dec\" so we use find_element_by_partial_link_text()\n",
    "    next_button = browser.find_element(By.PARTIAL_LINK_TEXT,'Sun ') \n",
    "    next_button.click()\n",
    "except NoSuchElementException:  #if such element does not exist, just stop looping\n",
    "    print(\"something went wrong. There was no Sunday link.\")\n",
    "    \n",
    "# load current view of the page into a soup\n",
    "soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "\"\"\"\n",
    "1. Find all the elements of class pros and print them \n",
    "2. These values include today's sunrise and sunset time, and the following 13 days.\n",
    "3. `browser.page_source` always get the whole page, so we can only find all\n",
    "4. A not smart, but workable solution is to count how many days between today and next sunday \n",
    "   and then choose the right element of all sunrise_tag list.\n",
    "\"\"\"\n",
    "# The whole list\n",
    "sunrise_tag = soup.find_all(\"span\", {\"class\" : 'wr-c-astro-data__time'})\n",
    "# How many days between today and the next sunday\n",
    "diff = int(next_button.get_attribute('id')[-1])\n",
    "\n",
    "print(\"Sunrise next Sunday: \", sunrise_tag[2*diff].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add33c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 08:32\n",
      "1 16:15\n",
      "2 08:31\n",
      "3 16:17\n",
      "4 08:29\n",
      "5 16:18\n",
      "6 08:28\n",
      "7 16:20\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(i, sunrise_tag[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb0b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecad658f",
   "metadata": {},
   "source": [
    "## Using API to access Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2606ce",
   "metadata": {},
   "source": [
    "Tweepy is a library that interfaces with the Twitter API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "294ab621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.12.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 2.6 MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib<2,>=1.2.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tweepy) (2.27.1)\n",
      "Collecting oauthlib<4,>=3.2.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-1.3.1 tweepy-4.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "import tweepy\n",
    "# weeeply is a python library for accessing twitter data via twitter API. \n",
    "# # below I am sharing my demo credenmtials, they will work for testing it,\n",
    "# but for your project you'll need to create  your own credentials.\n",
    "# - create a twitter app with your twitter avound (one per group will do) https://developer.twitter.com/en/apps\n",
    "# - follow the tutorial on tweepy to set it up https://tweepy.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a02a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bearer_token = 'AAAAAAAAAAAAAAAAAAAAAMi%2BYAEAAAAA%2F2LLeju%2BgWlNK34g6PMT14scXzQ%3DHa0gE8PJoBnMVlnyoC3648USErcR6E86QadKgbKlBMIrKVNiYz'  # please generate it from twitter developer by yourself and put it here\n",
    "client = tweepy.Client(Bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c23fbb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for Chinese New Year events? Look no further than our Eventbrite: https://t.co/dvChrFbzW3\n",
      "\n",
      "#ChineseNewYear2023 #YearOfTheRabbit #China #culture #museum #EVENT #ceilidh #dance #family #children #crafting #scavengerhunt #museum #activity\n",
      "Master’s Degree Scholarships by the MasterCard Foundation at the University of Edinburgh. \n",
      "\n",
      "Eligible for both online and on campus study. \n",
      "\n",
      "Follow the link for more details:  https://t.co/kLkFEXqxNb https://t.co/inzs7MxHVG\n",
      "RT @RoyalCentral: The Princess Royal, as Chancellor of the University of Edinburgh, will visit the FastBlade Structural Testing facility in…\n",
      "RT @AHFdoco: @KayBurley @elliebgomersall Our Film Adult Human Female was cancelled by student trans rights activists at Edinburgh Universit…\n",
      "RT @RoyalCentral: The Princess Royal, as Chancellor of the University of Edinburgh, will visit the FastBlade Structural Testing facility in…\n",
      "We had the pleasure of hosting @geraldchirinda and @munangenda from the @FutureAfriForum at the University of Edinburgh. Fascinating discussions on Africa, health and development. Inspiring to hear from leaders working towards a better future for the continent. https://t.co/KzD5qq9Emn\n",
      "RT @shefmethods: Younger voters ‘more likely to return to the ballot box – a new study shows. The report released today was produced by the…\n",
      "A modeling study led by the School of GeoSciences at the University of Edinburgh:\n",
      "the combined effect of export restrictions, increased areng costs and mid-2022 fertilizer prices could cause food costs to rise by 81% in 2023 compared to 2021 levels.\n",
      "https://t.co/BcbNrrtCni\n",
      "RT @uoe_online: Aiming to read more books in 2023? Check out our amazing online course called ‘How to Read a Novel’ by Benjamin Bateman – a…\n",
      "University of Edinburgh staff and postgraduate students still have time to sign up for our first digital skills session of the year!\n",
      "Creative Commons Quick Start - A short introduction to Creative Commons licences, 18 Jan 12.00 - 12.30. \n",
      "https://t.co/EQ3nvDvSsu https://t.co/LkOojLa0N7\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweepy.Paginator(client.search_recent_tweets, \"University of Edinburgh\",\n",
    "                              max_results=100).flatten(limit=10):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297db8f",
   "metadata": {},
   "source": [
    "**More details, please refer to https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be557039",
   "metadata": {},
   "source": [
    "## Scraping tweets with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd428a",
   "metadata": {},
   "source": [
    "In this exercise we will use selenium to copy-paste some tweets straight from the twitter website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db35ce2",
   "metadata": {},
   "source": [
    "Be aware that there are terms and conditions about how you can use these coppied data. If you abuse or overuse scraping, twitter might block or throttle (slow down) your access to their site. (like, don't scrpate 1000s of tweets in 100 parrallel selenium windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f3e9a",
   "metadata": {},
   "source": [
    "This time, we import selenium first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f8cebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8a243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('chromedriver') # mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cf5fb",
   "metadata": {},
   "source": [
    "The webdriver object can launch Internet Explorer, Firefox, and Chrome. Despite your preference, the ChromeDriver (which is a light version of Chrome) is the most widely used and complete one. You can use it to start a twitter page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5127c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch the browser\n",
    "browser = get_a_browser()\n",
    "\n",
    "# launch the Twitter search page\n",
    "twitter_url = u'https://twitter.com/search?q='\n",
    "\n",
    "# Add the search term\n",
    "query = u'%40edinburgh'\n",
    "# note: %40 is a code for @ symbol, so we're asking for the tweets with @edinburgh\n",
    "\n",
    "# Create the url\n",
    "url = twitter_url+query\n",
    "\n",
    "# Get the page\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40a064",
   "metadata": {},
   "source": [
    "Let's do this again and unleash the power of Selenium by using keyboard controls to manipulate a page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdff082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets scraped:  4\n",
      "\n",
      "--NEXT TWEET---\n",
      " 151 \n",
      "-----\n",
      "\n",
      "\n",
      "--NEXT TWEET---\n",
      " 102 \n",
      "-----\n",
      "\n",
      "\n",
      "--NEXT TWEET---\n",
      " 16 \n",
      "-----\n",
      "\n",
      "\n",
      "--NEXT TWEET---\n",
      " 38 \n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "browser = get_a_browser()\n",
    "browser.get(url)\n",
    "\n",
    "# Let the Tweets load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find the body of the HTML page\n",
    "body = browser.find_element(By.TAG_NAME,'body')\n",
    "\n",
    "# Keep scrolling down using a simulation of the PAGE_DOWN button\n",
    "for _ in range(5):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    \n",
    "# Get the tweets scores by their class (similar to Beautifulsoup's find())\n",
    "retweets = browser.find_elements(By.XPATH,\"//div[@data-testid='retweet']\");\n",
    "\n",
    "print(\"number of tweets scraped: \", len(retweets))\n",
    "\n",
    "# Print Tweets\n",
    "for retweet in retweets:\n",
    "    print(\"\\n--NEXT TWEET---\\n\", retweet.text, \"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b39e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
